COR GAZE DETECTION LIBRARY - TECHNICAL DOCUMENTATION
==================================================

VERSION: 1.0.2
LAST UPDATED: October 2024
MAJOR UPDATE: Integrated CLI functionality, enhanced C extension documentation, professional user experience

TABLE OF CONTENTS
-----------------
1. OVERVIEW
2. INSTALLATION AND SETUP
3. API REFERENCE
4. CONFIGURATION FILES
5. ALGORITHMS AND METHODS
6. PERFORMANCE OPTIMIZATION
7. TROUBLESHOOTING
8. EXAMPLES AND USE CASES
9. DEVELOPMENT NOTES

1. OVERVIEW
-----------
Cor is a comprehensive gaze detection library implemented in Python using OpenCV and matplotlib. 
It provides automated eye tracking and gaze analysis capabilities for video processing 
applications. The library uses proven computer vision algorithms for robust detection 
across various lighting conditions and head poses.

Key Features:
- Multi-format video processing (MP4, AVI, MOV, MKV, WMV, FLV, WEBM)
- Automatic calibration system for eye and gaze detection
- Professional heatmap generation with exact video dimension matching
- Clean, publication-ready output (no titles, legends, or scaling artifacts)
- Video visualization with gaze tracking overlays
- Real-time progress tracking with Unicode progress bars (█)
- Pure Python implementation - no compilation required
- Cross-platform compatibility (Windows, macOS, Linux)
- Comprehensive configuration management (133+ parameters)
- Repository organization with testing files in dedicated folder

2. INSTALLATION AND SETUP
--------------------------

System Requirements:
- Operating System: Windows, macOS, Linux
- Python: 3.7 or higher
- OpenCV: 4.5 or higher (opencv-python package)
- NumPy: 1.19 or higher
- Matplotlib: 3.3 or higher
- Memory: Minimum 4GB RAM (8GB recommended for large videos)
- Storage: 100MB for library + space for output files

Installation Methods:

Method 1 - PyPI Installation:
    pip install cor

Method 2 - Source Installation:
    git clone https://github.com/victorcynzo/cor
    cd cor
    pip install -e .

Method 3 - Direct Installation:
    pip install opencv-python matplotlib numpy Pillow
    pip install -e .

Method 2 - Source Installation:
    git clone https://github.com/cor-team/cor.git
    cd cor
    pip install -e .

Method 3 - C Extension Installation (High Performance):

Prerequisites:
- C++ compiler (Visual Studio 2019+ on Windows, GCC 7+ on Linux, Xcode on macOS)
- OpenCV development headers and libraries (version 4.5+)
- Python development headers
- CMake (optional, for advanced builds)

Windows Installation:
    # Install Visual Studio Build Tools or Visual Studio Community
    # Download from: https://visualstudio.microsoft.com/downloads/
    
    # Install OpenCV development package
    pip install opencv-contrib-python-headless
    
    # Clone and build
    git clone https://github.com/cor-team/cor.git
    cd cor
    python setup.py build_ext --inplace
    pip install -e .

Linux/Ubuntu Installation:
    # Install development tools
    sudo apt-get update
    sudo apt-get install build-essential python3-dev pkg-config
    
    # Install OpenCV development headers
    sudo apt-get install libopencv-dev libopencv-contrib-dev
    # Alternative: sudo apt-get install libopencv-dev python3-opencv
    
    # Install Python packages
    pip install opencv-contrib-python-headless numpy
    
    # Clone and build
    git clone https://github.com/cor-team/cor.git
    cd cor
    python setup.py build_ext --inplace
    pip install -e .

macOS Installation:
    # Install Xcode command line tools
    xcode-select --install
    
    # Install OpenCV via Homebrew
    brew install opencv
    
    # Install Python packages
    pip install opencv-contrib-python-headless numpy
    
    # Clone and build
    git clone https://github.com/cor-team/cor.git
    cd cor
    python setup.py build_ext --inplace
    pip install -e .

Method 4 - Automated Build and Test:
    python build_and_test.py

C Extension Verification:
    python -c "import cor; v = cor.version(); print(f'Mode: {v[\"mode\"]}, C Extension: {v[\"c_extension\"]}')"
    
    Expected output for successful C extension:
    Mode: C Extension, C Extension: True
    
    If you see "Python fallback", the C extension failed to build.

Troubleshooting C Extension Build:
- Windows: Ensure Visual Studio Build Tools are installed and in PATH
- Linux: Install missing development packages: sudo apt-get install python3-dev libopencv-dev
- macOS: Update Xcode command line tools: xcode-select --install
- All platforms: Verify OpenCV installation: python -c "import cv2; print(cv2.__version__)"

Verification:
    python -c "import cor; print(cor.__version__)"

RUNNING C EXTENSION VS PYTHON FALLBACK:

The Cor library automatically detects which implementation is available and uses the best one:

1. If C extension is successfully compiled and installed → Uses C Extension mode
2. If C extension is not available → Falls back to Python implementation

Detection and Usage:
    import cor
    
    # Check which version is running
    version_info = cor.version()
    print(f"Mode: {version_info['mode']}")
    print(f"C Extension Available: {version_info['c_extension']}")
    
    # Usage is identical regardless of mode
    cor.run("video.mp4", "--visualize")

Mode-Specific Features:
    Python Fallback Mode:
    - All basic gaze detection functionality
    - Heatmap generation and visualization
    - Configuration management
    - Frame extraction and benchmarking
    - CLI interface
    
    C Extension Mode (Additional Features):
    - 10-100x faster processing
    - Real-time camera processing
    - Advanced attention analysis
    - Advanced heatmap modes
    - JSON data export
    - Better memory management

Performance Comparison:
    Python Fallback: ~15-30 FPS processing, suitable for videos up to 1080p
    C Extension: ~60-150 FPS processing, handles 4K videos efficiently

Switching Between Modes:
    - To force Python fallback: Rename or remove the compiled C extension files
    - To use C extension: Follow C Extension Installation instructions above
    - The library will automatically use the best available implementation

3. API REFERENCE
----------------

3.1 COMMAND LINE INTERFACE

cor.cli()
    Description: Built-in command-line interface for Cor library
    Usage: Can be called directly from terminal after installation
    Entry Points:
        - cor <arguments>                    # Direct command (after pip install)
        - python -m cor <arguments>          # Python module execution
        - python -c "import cor; cor.cli()"  # Direct function call
    
    Command Line Arguments:
        video_file                           # Path to input video file (required for most operations)
        --visualize                         # Generate visualization video with gaze overlay
        --calibrate                         # Run both eye and gaze calibration before analysis
        --eye-calibrate                     # Run only eye detection calibration
        --gaze-calibrate                    # Run only gaze direction calibration
        --validate                          # Validate video file and show properties
        --extract-frames N                  # Extract N frames from video for preview
        --benchmark N                       # Run performance benchmark (default: 100 frames)
        --config PARAM VALUE                # Set configuration parameter
        --get-config PARAM                  # Get configuration parameter value
        --version                           # Show version information
        --help-cor                          # Show Cor library help information
        --help                              # Show CLI help
    
    Examples:
        cor video.mp4                       # Basic gaze detection
        cor video.mp4 --visualize          # With visualization video
        cor video.mp4 --calibrate --visualize  # Full workflow
        cor --version                       # Show version
        cor --config heatmap_color_scheme sequential_red  # Set config
        cor video.mp4 --validate           # Validate video
        cor video.mp4 --benchmark 50       # Performance test

3.2 CORE FUNCTIONS

cor.help()
    Description: Displays comprehensive help information for all available functions
    Parameters: None
    Returns: None (prints to stdout)
    Example: cor.help()

cor.calibrate_eyes(video_file)
    Description: Interactive eye detection calibration interface
    Parameters:
        video_file (str): Path to input video file
    Returns: None
    Side Effects: 
        - Creates/updates eye-detection-values.txt
        - Opens GUI calibration window
    Example: cor.calibrate_eyes("sample.mp4")
    
    Calibration Process:
        1. Extracts 20 evenly distributed frames from video
        2. Displays each frame with adjustable detection boundaries
        3. User adjusts ellipses/circles around eyes and pupils
        4. Saves detection parameters to configuration file
        5. Handles existing calibration data with merge/overwrite options

cor.calibrate_gaze(video_file)
    Description: Interactive gaze direction calibration interface
    Parameters:
        video_file (str): Path to input video file
    Returns: None
    Side Effects:
        - Creates/updates gaze-direction-values.txt
        - Opens GUI calibration window
    Example: cor.calibrate_gaze("sample.mp4")
    
    Calibration Process:
        1. Extracts 20 evenly distributed frames from video
        2. Displays frames with gaze direction indicator (green ball)
        3. Shows connecting lines between gaze point and pupils
        4. User adjusts gaze direction parameters
        5. Saves calibration data to configuration file

cor.run(video_file, *args)
    Description: Executes gaze detection analysis on video file
    Parameters:
        video_file (str): Path to input video file
        *args: Optional arguments (currently supports "--visualize")
    Returns: None
    Side Effects: Creates output files based on video name
    
    Standard Output Files:
        - {videoname}_heatmap-pure.jpg: Pure heatmap visualization
        - {videoname}_heatmap-overlay.jpg: Heatmap overlaid on 10th frame
    
    With --visualize Flag:
        - {videoname}_heatmap.{ext}: Full video with gaze overlay
    
    Examples:
        cor.run("video.mp4")
        cor.run("video.mp4", "--visualize")

cor.version()
    Description: Returns detailed version information
    Parameters: None
    Returns: Dictionary with version details
    Example: version_info = cor.version()

cor.get_config(param_name, config_file="cor.txt")
    Description: Retrieves configuration parameter value from config files
    Parameters:
        param_name (str): Name of configuration parameter
        config_file (str, optional): Configuration file path (default: "cor.txt")
    Returns: String value of parameter or None if not found
    Supported Files: cor.txt, eye-detection-values.txt, gaze-direction-values.txt
    Example: value = cor.get_config("heatmap_color_scheme")
    Example: eye_param = cor.get_config("scale_factor", "eye-detection-values.txt")

cor.set_config(param_name, param_value, config_file="cor.txt")
    Description: Sets configuration parameter value in config files
    Parameters:
        param_name (str): Name of configuration parameter
        param_value (str): Value to set
        config_file (str, optional): Configuration file path (default: "cor.txt")
    Returns: Boolean indicating success
    Side Effects: Creates config file if it doesn't exist, updates existing parameters
    Example: cor.set_config("heatmap_color_scheme", "sequential_red")
    Example: cor.set_config("gaze_sensitivity", "1.5", "gaze-direction-values.txt")

cor.validate_video(video_file)
    Description: Validates video file and returns properties
    Parameters:
        video_file (str): Path to video file
    Returns: Dictionary with validation results and video properties
    Example: info = cor.validate_video("sample.mp4")

cor.extract_frames(video_file, num_frames=10, output_dir="frames")
    Description: Extracts evenly distributed sample frames from video for preview
    Parameters:
        video_file (str): Path to video file
        num_frames (int): Number of frames to extract (default: 10)
        output_dir (str): Directory to save frames (default: "frames")
    Returns: List of extracted frame file paths
    Side Effects: Creates output directory if it doesn't exist
    Progress: Shows Unicode progress bar during extraction
    Output Format: JPG images named frame_001.jpg, frame_002.jpg, etc.
    Example: frames = cor.extract_frames("video.mp4", 20, "preview_frames")
    Use Cases: Video quality assessment, frame selection, preview generation

cor.benchmark(video_file, max_frames=100)
    Description: Runs comprehensive performance benchmark on video processing
    Parameters:
        video_file (str): Path to video file
        max_frames (int): Maximum frames to process for benchmark (default: 100)
    Returns: Dictionary with detailed performance metrics
    Progress: Shows real-time benchmarking progress with Unicode progress bar
    Metrics Returned:
        - frames_processed: Number of frames analyzed
        - processing_time: Total processing time in seconds
        - processing_fps: Processing speed in frames per second
        - detection_rate: Percentage of frames with successful gaze detection
        - detections: Total number of successful detections
        - video_fps: Original video frame rate
    Example: results = cor.benchmark("video.mp4", 200)
    Use Cases: Hardware optimization, performance tuning, system requirements assessment

cor.analyze_attention(video_file)
    Description: Analyzes attention patterns including fixations and saccades
    Parameters:
        video_file (str): Path to video file
    Returns: Dictionary with attention analysis results
    Example: analysis = cor.analyze_attention("video.mp4")

cor.generate_advanced_heatmap(video_file, mode="density", output_path=None)
    Description: Generates advanced heatmaps with specific visualization modes
    Parameters:
        video_file (str): Path to video file
        mode (str): Heatmap mode ("density", "fixation", "saccade")
        output_path (str, optional): Output file path
    Returns: None
    Example: cor.generate_advanced_heatmap("video.mp4", "fixation", "fixation_map.jpg")

cor.init_realtime(camera_id=0)
    Description: Initializes real-time camera processing
    Parameters:
        camera_id (int): Camera device ID (default: 0)
    Returns: Boolean indicating success
    Example: success = cor.init_realtime(0)

cor.process_realtime_frame()
    Description: Processes single frame from camera in real-time
    Parameters: None
    Returns: Dictionary with gaze point data
    Example: gaze_data = cor.process_realtime_frame()

cor.cleanup_realtime()
    Description: Cleans up real-time processing resources
    Parameters: None
    Returns: None
    Example: cor.cleanup_realtime()

cor.export_analysis(video_file, output_path=None)
    Description: Exports detailed analysis results to JSON file
    Parameters:
        video_file (str): Path to video file
        output_path (str, optional): Output JSON file path
    Returns: String path to exported file
    Example: export_path = cor.export_analysis("video.mp4")

3.2 INTERNAL FUNCTIONS (C++ IMPLEMENTATION)

detect_eyes(frame, calibration_data)
    Description: Detects eye regions in a single frame
    Implementation: Haar cascades + custom ellipse fitting
    Returns: Eye bounding boxes and pupil centers

detect_gaze_direction(eye_data, calibration_data)
    Description: Calculates gaze direction from eye detection data
    Implementation: Pupil center analysis + geometric calculations
    Returns: Gaze vector coordinates

generate_heatmap(gaze_data, frame_dimensions, color_scheme)
    Description: Creates heatmap from accumulated gaze data
    Implementation: Gaussian kernel density estimation
    Returns: Heatmap image array

4. CONFIGURATION FILES
----------------------

4.1 eye-detection-values.txt
Format: Key-value pairs, one per line
Purpose: Stores eye detection calibration parameters

Example Content:
    eye_cascade_scale_factor=1.1
    eye_cascade_min_neighbors=5
    eye_region_width_factor=0.3
    eye_region_height_factor=0.4
    pupil_detection_threshold=50
    pupil_min_radius=5
    pupil_max_radius=30
    left_eye_offset_x=0
    left_eye_offset_y=0
    right_eye_offset_x=0
    right_eye_offset_y=0

4.2 gaze-direction-values.txt
Format: Key-value pairs, one per line
Purpose: Stores gaze direction calibration parameters

Example Content:
    gaze_sensitivity_x=1.0
    gaze_sensitivity_y=1.0
    gaze_offset_x=0
    gaze_offset_y=0
    pupil_to_gaze_ratio=0.8
    gaze_smoothing_factor=0.3
    min_confidence_threshold=0.7
    max_gaze_angle=45

4.3 cor.txt
Format: Key-value pairs with descriptions
Purpose: General configuration and heatmap settings

Example Content:
    # Heatmap Configuration
    heatmap_color_scheme=sequential_blue
    # Options: sequential_blue, sequential_red, sequential_green, 
    #          diverging_blue_red, diverging_green_red, 
    #          categorical_5, categorical_7
    
    heatmap_intensity_multiplier=1.0
    # Controls overall heatmap brightness (0.1 - 5.0)
    
    heatmap_blur_radius=15
    # Gaussian blur radius for heatmap smoothing (5 - 50)
    
    heatmap_resolution_factor=1.0
    # Resolution multiplier for heatmap generation (0.5 - 2.0)
    
    # Video Processing
    frame_skip_factor=1
    # Process every Nth frame (1 = all frames, 2 = every other frame)
    
    output_video_quality=0.8
    # Video compression quality for --visualize output (0.1 - 1.0)
    
    # Visualization
    gaze_circle_radius=10
    # Radius of gaze indicator circle in pixels
    
    gaze_circle_color=0,255,0
    # RGB color values for gaze indicator (0-255 each)
    
    pupil_line_thickness=2
    # Thickness of lines connecting gaze point to pupils
    
    pupil_line_color=255,255,0
    # RGB color values for pupil connection lines

5. ALGORITHMS AND METHODS
-------------------------

5.1 EYE DETECTION ALGORITHM
- Primary Method: Haar Cascade Classifiers
- Backup Method: Template matching with normalized correlation
- Pupil Detection: Circular Hough Transform + intensity analysis
- Refinement: Ellipse fitting for improved accuracy

5.2 GAZE ESTIMATION ALGORITHM
- Method: Pupil center corneal reflection (PCCR) approximation
- Calibration: User-defined reference points for accuracy
- Smoothing: Temporal filtering to reduce noise
- Confidence Scoring: Quality assessment for each detection

5.3 HEATMAP GENERATION (v1.0.1 Major Fix)
- Density Estimation: 2D Gaussian kernel density estimation with meshgrid coordinates
- Exact Dimensions: Output images match input video dimensions precisely (no scaling)
- Clean Output: Professional visualization without titles, legends, or artifacts
- Gaussian Blobs: Configurable sigma parameter (default: 25 pixels)
- Normalization: Min-max scaling with configurable intensity multipliers
- Color Mapping: Multiple schemes with customizable palettes (hot, viridis, plasma, etc.)
- Overlay Blending: Alpha compositing for frame overlay (default: 0.6 alpha)
- Figure Optimization: Matplotlib figure sizing calculated from video resolution
- DPI Control: 100 DPI output for consistent quality across platforms

6. PERFORMANCE OPTIMIZATION
---------------------------

6.1 PROCESSING OPTIMIZATIONS
- Multi-threading: Parallel processing of video frames
- Memory Management: Efficient buffer allocation and reuse
- Frame Skipping: Configurable frame sampling for speed
- ROI Processing: Region of interest focusing for efficiency

6.2 PROGRESS TRACKING (v1.0.1 Enhancement)
- Real-time Progress Bars: Visual feedback for all video processing operations
- Unicode Block Characters: Clear progress visualization using █ characters
- Operation-specific Messages: Contextual status information for each process
- Frame-level Tracking: Detailed progress for video analysis operations
- Calibration Progress: Step-by-step progress during interactive calibration
- Terminal Integration: Proper carriage return and flush operations for smooth updates
- Update Frequency: Progress updates every 10 frames or at completion
- Cross-platform Compatibility: Works on Windows, macOS, and Linux terminals
- Performance Impact: Minimal overhead (~1% processing time)

6.3 CONFIDENCE ASSESSMENT
- Automatic Accuracy Evaluation: Post-processing confidence analysis
- Detection Rate Analysis: Percentage of successful gaze detections
- Confidence Distribution: Breakdown of high/medium/low confidence points
- Overall Accuracy Score: Composite reliability metric (0-100%)
- Interpretation Guidelines: Clear recommendations based on confidence levels
- Quality Recommendations: Suggestions for improving detection accuracy

6.4 MEMORY USAGE
- Typical Usage: 50-200MB for standard video processing
- Large Videos: Streaming processing to minimize memory footprint
- Calibration: Temporary storage of 20 frames (~100MB)

6.5 PERFORMANCE BENCHMARKS
- Standard Video (720p, 30fps): ~15-25 fps processing speed
- High Resolution (1080p+): ~8-15 fps processing speed
- Calibration Interface: Real-time interaction (30+ fps)

7. TROUBLESHOOTING
------------------

7.1 COMMON ISSUES

Issue: "OpenCV not found" error
Solution: Install OpenCV with pip install opencv-python

Issue: Poor eye detection accuracy
Solution: Run cor.calibrate_eyes() for video-specific tuning

Issue: Gaze direction seems incorrect
Solution: Use cor.calibrate_gaze() to set proper reference points

Issue: Video format not supported
Solution: Convert video to MP4 format using ffmpeg

Issue: Out of memory errors
Solution: Increase frame_skip_factor in cor.txt or use smaller videos

Issue: Heatmap dimensions don't match video (v1.0.1 FIXED)
Solution: Update to v1.0.1 - heatmaps now match video dimensions exactly

Issue: Progress bars not showing
Solution: Update to v1.0.1 - Unicode progress bars now work in Python mode

Issue: Heatmap has titles/legends (v1.0.1 FIXED)
Solution: Update to v1.0.1 - clean output without titles or legends

Issue: Testing files cluttering project
Solution: Testing files moved to testing_examples/ folder in v1.0.1

7.2 DEBUG MODE
Enable debug output by setting environment variable:
    export COR_DEBUG=1 (Linux/macOS)
    set COR_DEBUG=1 (Windows)

8. EXAMPLES AND USE CASES
-------------------------

8.1 RESEARCH APPLICATIONS
- Eye-tracking studies in psychology and neuroscience
- User interface usability testing
- Reading pattern analysis
- Attention and focus measurement

8.2 COMMERCIAL APPLICATIONS
- Marketing research and advertisement effectiveness
- Driver attention monitoring systems
- Accessibility technology development
- Gaming and virtual reality interfaces

8.3 SAMPLE WORKFLOWS

Basic Analysis Workflow:
    1. Import video file
    2. Run cor.run("video.mp4") for quick analysis
    3. Review heatmap outputs
    4. Adjust parameters if needed

Precision Analysis Workflow:
    1. Import video file
    2. Run cor.calibrate_eyes("video.mp4")
    3. Run cor.calibrate_gaze("video.mp4")
    4. Run cor.run("video.mp4", "--visualize")
    5. Review all outputs and fine-tune parameters

Batch Processing Workflow:
    1. Calibrate using representative video
    2. Process multiple videos with same settings
    3. Compare heatmap outputs across videos
    4. Generate summary statistics

9. DEVELOPMENT NOTES
--------------------

9.1 ARCHITECTURE
- Core Engine: C++ implementation for performance
- Python Bindings: Simplified interface for ease of use
- Configuration System: Text-based for user accessibility
- Modular Design: Separate components for different functions

9.2 IMPLEMENTED ADVANCED FEATURES
- Real-time camera input support with cor.init_realtime()
- Advanced attention pattern analysis with fixation and saccade detection
- Multiple heatmap visualization modes (density, fixation, saccade)
- JSON export of detailed analysis results
- Performance benchmarking and optimization tools

9.3 FUTURE ENHANCEMENTS
- Machine learning-based eye detection
- 3D gaze vector estimation
- Multi-person tracking capabilities
- Cloud processing integration
- Mobile device support

9.3 CONTRIBUTING
See CONTRIBUTING.md for development guidelines and coding standards.

9.4 LICENSE
MIT License - see LICENSE file for full terms.

---
For additional support, visit: https://github.com/cor-team/cor
Documentation updates: https://cor-gaze.readthedocs.io/